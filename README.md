# CodeTutorAI â€“ Turn GitHub Repos into Interactive Tutorials

>*Lost in someone else's GitHub project? Build an AI Code Explainer to generate clear explanations! This tutorial shows you how to create an agent that analyzes repositories and produces easy-to-understand guides.*

![CodeTutorAI Banner](assets/CodeTutorAI-Banner.png)

```plaintext
          .--""--.           _______          __       _______       __              _______ ___
         |________|         |   _   .-----.--|  .-----|       .--.--|  |_.-----.----|   _   |   |
             ||             |.  1___|  _  |  _  |  -__|.|   | |  |  |   _|  _  |   _|.  1   |.  |
             ()             |.  |___|_____|_____|_____`-|.  |-|_____|____|_____|__| |.  _   |.  |
      <-------------->      |:  1   |                   |:  |                       |:  |   |:  |
     / \____________/ \     |::.. . |                   |::.|                       |::.|:. |::.|
    /___\__________/___\    `-------'                   `---'                       `--- ---`---'
```

**CodeTutorAI** is an AI-powered system that transforms any GitHub repository into a beginner-friendly, tutorial-style walkthrough. It analyzes the structure, abstractions, and relationships within a codebase to produce a multi-chapter guide that helps you deeply understand the inner workings of unfamiliar projects.

---

## ğŸ” What Is CodeTutorAI?

CodeTutorAI acts as a digital oracle for codebases â€” using AI to reveal the design, purpose, and interactions between the components of any GitHub repository. Think of it as a magnifying glass for developers who want to uncover the story behind someone elseâ€™s code.

### Core Features

- ğŸ§  Uses LLMs (Google Gemini, OpenAI, Anthropic) to identify and explain key abstractions.
- ğŸ•¸ï¸ Maps out relationships and architecture visually.
- ğŸ“˜ Generates structured Markdown tutorials.
- ğŸŒ Output is ready for GitHub Pages or docs hosting.
- ğŸŒ Supports multiple languages for global accessibility (LLM dependent).
- ğŸ“Š Generates Mermaid diagrams for visual understanding.
- ğŸ¯ Adjustable depth levels (basic, intermediate, advanced) for different expertise levels.
- ğŸ–¥ï¸ Interactive HTML viewer for better reading experience.
- âœ¨ **NEW:** Interactive Streamlit UI for easy configuration and generation.
- â˜ï¸ **NEW:** Support for Google Gemini, OpenAI, and Anthropic models with dynamic model selection.
- ğŸ’¾ **NEW:** Persistent LLM response caching (enabled by default) with manual clearing via UI.
- ğŸ”„ **NEW:** Option to force regeneration, ignoring the cache.
- ğŸ“‚ **NEW:** Structured output directories per repository (`<user>_<repo>`).
- ğŸ“œ **NEW:** Generation history tracking (URL, config, output path) saved in `generation_history.json`.
- â±ï¸ **NEW:** Displays total generation time in the UI.
- ğŸ–±ï¸ **NEW:** GitHub URL history dropdown in the UI for quick selection.

---

## âš™ï¸ How It Works

CodeTutorAI operates as a modular AI workflow that progresses through the following steps:

```mermaid
graph TD
    subgraph "User Interfaces"
        UI_CLI["CLI (cli.py)"]
        UI_ST["Streamlit UI (streamlit_app.py)"]
    end

    subgraph "CodeTutorAI Core Logic (codetutorai/)"
        Core_Flow["Tutorial Flow (flow.py)"]
        Core_Nodes["Nodes (nodes/)"]
        Core_Utils["Utilities (utils/)"]
    end

    subgraph "External Services / Data"
        Ext_Git["GitHub / Local Repo"]
        Ext_Web["Website (Optional)"]
        Ext_LLM["LLM API (Google, OpenAI, Anthropic)"]
    end

    UI_CLI -- Runs --> Core_Flow;
    UI_ST -- Runs --> Core_Flow;


    Core_Flow --> Core_Nodes;
    Core_Nodes --> Core_Utils;
    Core_Nodes --> Ext_LLM;

    Core_Nodes -- Fetches --> Ext_Git;
    Core_Nodes -- Fetches --> Ext_Web;

    %% e.g., llm_client, history_manager
    Core_Utils --> Ext_LLM;

    style UI_ST fill:#FF4B4B,stroke:#333,stroke-width:2px
```

Each node is powered by prompts to a large language model (LLM), enabling intelligent interpretation of even complex, multi-language codebases. The Streamlit UI provides a user-friendly way to configure and run the generation process.

---

## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
# Clone the repository
git clone https://github.com/Mathews-Tom/CodeTutorAI.git
cd CodeTutorAI
```

### 2. Create and Activate Virtual Environment

```bash
# Create a virtual environment (recommended)
python3 -m venv .venv

# Activate it
# On macOS/Linux:
source .venv/bin/activate
# On Windows:
# .venv\Scripts\activate
```

### 3. Install Dependencies

```bash
# Using pip (within the activated environment)
pip install -r requirements.txt

# Or install in editable mode for development
pip install -e .

# Using uv (optional, faster)
# pip install uv
# uv pip install -r requirements.txt
```

### 4. Set Up Environment Variables

Create a `.env` file in the project root directory (`CodeTutorAI/`) and add your API keys. The application requires the key for the selected LLM provider.

```bash
# Example .env file
GOOGLE_API_KEY=your_google_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
```
The application will load these automatically.

### 5. Run CodeTutorAI

#### Using the Streamlit UI (Recommended)

This is the easiest way to use CodeTutorAI. Ensure your virtual environment is activated.

```bash
streamlit run streamlit_app.py
```
This will open the web interface in your browser. Configure the options and click "Generate Tutorial".

**Key UI Features:**
*   Select LLM Provider (Google, OpenAI, Anthropic) and specific Model.
*   Enter GitHub Repository URL (with history dropdown).
*   Configure output directory, depth, language, formats.
*   Enable/disable diagram generation and auto-viewer opening.
*   Manage caching: Enable/disable, clear cache, force regeneration.
*   View generation progress and final status (including time taken and cache status).
*   Reset application state.

#### As a Command-Line Tool

After installation (`pip install -e .`), you can run CodeTutorAI from the command line (ensure the virtual environment is active):

```bash
# Basic usage
codetutorai https://github.com/SomeUser/SomeProject --output-dir ./tutorial_output

# Example with options
codetutorai https://github.com/tiangolo/fastapi \
  --output-dir ./fastapi_tutorial \
  --depth advanced \
  --language en \
  --llm-provider Google \
  --output-formats markdown,viewer \
  --diagrams \
  --open-viewer
```

#### As a Python Module

```bash
# Ensure virtual environment is active
python -m codetutorai.cli https://github.com/SomeUser/SomeProject --output-dir ./docs
# Or with python3 explicitly
python3 -m codetutorai.cli https://github.com/SomeUser/SomeProject --output-dir ./docs
```

#### CLI Optional Flags

```bash
  --web-url URL           # Additional web context URL
  --include PATTERNS      # Comma-separated file patterns to include (e.g., "*.py,*.js")
  --exclude PATTERNS      # Comma-separated file patterns to exclude (e.g., "test_*,*__pycache__*")
  --llm-provider PROVIDER # LLM provider (Google, OpenAI, Anthropic)
  --api-key KEY           # Override API key from .env
  --batch-size N          # Number of chapters to generate in parallel (default: 1)
  --output-formats F1,F2  # Output formats (markdown, html, pdf, viewer)
  --depth LEVEL           # Tutorial depth (basic, intermediate, advanced)
  --language CODE         # Tutorial language (ISO 639-1 code, e.g., es, fr, ja)
  --diagrams              # Generate Mermaid diagrams
  --open-viewer           # Open the HTML viewer automatically
  --cache-dir PATH        # Specify cache directory (default: .llm_cache)
  --no-cache              # Disable LLM caching
  --force-regeneration    # Force regeneration, ignore cache (CLI equivalent of UI checkbox)
  --verbose               # Enable verbose output
```

---

## ğŸ§± Folder Structure

```plaintext
CodeTutorAI/
â”œâ”€â”€ .env                            # Local environment variables (API keys)
â”œâ”€â”€ .env.example                    # Example environment variables
â”œâ”€â”€ .gitignore                      # Git ignore rules
â”œâ”€â”€ .venv/                          # Python virtual environment (created by user)
â”œâ”€â”€ assets/                         # Logos, banners, etc.
â”‚   â”œâ”€â”€ CodeTutorAI-Banner.png      # Project Banner Image
â”‚   â”œâ”€â”€ banner.txt                  # ASCII Art Banner
â”‚   â””â”€â”€ logo.txt                    # ASCII Art Logo
â”œâ”€â”€ docs/                           # Default output for generated documentation examples
â”œâ”€â”€ generation_history.json         # Tracks generation runs (created in output dir)
â”œâ”€â”€ install_dev.sh                  # Development installation script
â”œâ”€â”€ LICENSE                         # MIT License
â”œâ”€â”€ overview.md                     # Detailed system overview document
â”œâ”€â”€ pyproject.toml                  # Project metadata (PEP 621)
â”œâ”€â”€ README.md                       # This file
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ setup.py                        # Package setup script (uses pyproject.toml)
â”œâ”€â”€ src/                            # Source code directory
â”‚   â””â”€â”€ codetutorai/                # Main package (NEEDS MANUAL RENAME from enlightenai)
â”‚       â”œâ”€â”€ __init__.py             # Package initialization
â”‚       â”œâ”€â”€ cli.py                  # CLI entry point
â”‚       â”œâ”€â”€ flow.py                 # Defines the main tutorial generation workflow
â”‚       â”œâ”€â”€ nodes/                  # Node implementations for each step
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ node.py             # Base Node class
â”‚       â”‚   â””â”€â”€ ... (other node files)
â”‚       â””â”€â”€ utils/                  # Utility scripts
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ constants.py
â”‚           â”œâ”€â”€ formatting.py
â”‚           â”œâ”€â”€ history_manager.py  # NEW: Handles generation history
â”‚           â”œâ”€â”€ html_viewer.py
â”‚           â”œâ”€â”€ llm_client.py       # Enhanced LLM client
â”‚           â””â”€â”€ ... (other util files)
â”œâ”€â”€ streamlit_app.py                # NEW: Main Streamlit UI application script
â””â”€â”€ tutorial_output/                # Default output directory for tutorials
    â””â”€â”€ <user>_<repo>/              # NEW: Subdirectory for each generated repo
        â”œâ”€â”€ index.md
        â”œâ”€â”€ chapters/
        â”œâ”€â”€ diagrams/
        â””â”€â”€ viewer/                 # If HTML viewer format is selected
```

---

## ğŸ“˜ Example Output

Explore the `docs/` folder for examples or try CodeTutorAI on a real repo:

```bash
# Using the CLI tool
codetutorai https://github.com/tiangolo/fastapi

# Or using the Streamlit UI
streamlit run streamlit_app.py
# Then enter https://github.com/tiangolo/fastapi in the UI
```

---

## ğŸ›  Tech Stack

- **Python**
- **Streamlit** (for Web UI)
- **LLMs** (configurable: Google Gemini, OpenAI, Anthropic Claude)
- **Custom Flow Engine** for workflow orchestration
- **python-dotenv** (for environment variable loading)
- **diskcache** (for LLM response caching)
- **google-generativeai** (for Google Gemini API)
- **requests** (for Anthropic/OpenAI APIs)
- **gitpython** (used by FetchRepoGitinNode)
- **beautifulsoup4** (used by FetchWebNode)
- **tqdm** (for progress tracking)
- **tiktoken** (for token counting)
- **tenacity** (for retry logic)
- **Markdown + MermaidJS** for documentation output

---

## ğŸ“„ License

MIT License. See `LICENSE` for details.

---

> Built with ğŸ”® by [Mathews Tom](https://github.com/Mathews-Tom)
